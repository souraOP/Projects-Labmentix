{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    -     Glassdoor Salary Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Sourasish Mondal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "\n",
        "This project aims to predict salaries based on job postings from Glassdoor. The dataset contains various features such as job title, location, company size, industry, and more. We will perform exploratory data analysis (EDA), data preprocessing, and build regression models to predict salaries. The goal is to understand which factors most influence salary and create a model that can accurately predict salaries based on these factors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "[glassdoor_project ](https://github.com/souraOP/Projects-Labmentix/tree/6ce2f2cf33026aa6f943fdd26db8590e01aa8810/Glassdoor%20Project)  Provide your GitHub Link here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "Predict the average salary of a job listing using features such as company size, location, industry, job description, and company rating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgbUHAGgjLW"
      },
      "source": [
        "# **General Guidelines** : -  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      },
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFCDgL1KK7GI"
      },
      "outputs": [],
      "source": [
        "#%pip install contractions\n",
        "#%pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('glassdoor_jobs.csv')\n",
        "dataframe = pd.DataFrame(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape\n",
        "print(f\"Total 'rows' of the dataset: \", df.shape[0])\n",
        "print(f\"Total 'columns' of the dataset: \", df.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "print(\"Dataset Information: \\n\")\n",
        "print(df.info(), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "outputs": [],
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(), cmap=\"crest\")\n",
        "plt.show()\n",
        "print(\"The uniform colour of the heatmap indicates that there are NO missing values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "The dataset contains job postings from Glassdoor website with various features such as job title, salary estimate, job description, company name, location, headquarters, revenue, sector and many more. There are some missing values in the dataset, particularly in the 'Competitors' column. The dataset has both numerical and categorical features, which will require preprocessing before building the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "- **Job Title**: The title of the job posting.\n",
        "- **Salary Estimate**: The estimated salary range for the job given.\n",
        "- **Job Description**: A description/responsibilities of the job posting.\n",
        "- **Rating**: The company's rating on Glassdoor's website.\n",
        "- **Company Name**: The name of the company posting the job on the website.\n",
        "- **Location**: The location of the job.\n",
        "- **Headquarters**: The headquarters location of the company.\n",
        "- **Size**: The size of the company in terms of total employee count.\n",
        "- **Founded**: The year the company was founded.\n",
        "- **Type of ownership**: The type of ownership (private/public etc).\n",
        "- **Industry**: The industry of the company.\n",
        "- **Sector**: The sector of the company.\n",
        "- **Revenue**: The revenue of the company.\n",
        "- **Competitors**: Competitors of the company (with other company(s) if not then -1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Data Wrangling***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJF3rekwFvQ"
      },
      "source": [
        "### Data Wrangling Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STaCilcKK7GQ"
      },
      "outputs": [],
      "source": [
        "# Before cleaning the data\n",
        "print(df['Salary Estimate'], \"\\n\")\n",
        "print(df['Salary Estimate'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "outputs": [],
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "def clean_salary(salary):\n",
        "  if pd.isna(salary) or salary == '-1':\n",
        "    return np.nan\n",
        "\n",
        "  salary = salary.split('(')[0].strip()\n",
        "\n",
        "  if 'Employer Provided Salary:' in salary:\n",
        "    salary=salary.replace('Employer Provided Salary:', '').strip()\n",
        "\n",
        "  if 'Per Hour' in salary.lower():\n",
        "    salary = salary.lower().replace(' Per Hour', '').strip()\n",
        "    if '-' in salary:\n",
        "      min_rate, max_rate = salary.split('-')\n",
        "      min_rate = float(min_rate.replace('$', '').strip())\n",
        "      max_rate = float(max_rate.replace('$', '').strip())\n",
        "    else:\n",
        "\n",
        "      rate = float(salary.replace('$', '').strip())\n",
        "      min_rate = max_rate = rate\n",
        "\n",
        "    # Convert to annual (40 hours/week, 52 weeks/year)\n",
        "    min_annual = int(min_rate * 40 * 52 / 1000)\n",
        "    max_annual = int(max_rate * 40 * 52 / 1000)\n",
        "    return f\"{min_annual}K-{max_annual}K\"\n",
        "\n",
        "    # min_hourly, max_hourly = hourly_range.split('-')\n",
        "    # min_hourly = float(min_hourly.replace('$', '').strip())\n",
        "    # max_hourly=float(max_hourly.replace('$', '').strip())\n",
        "\n",
        "    # min_annual = min_hourly * 40 * 52 / 1000 # to thousands\n",
        "    # max_annual = max_hourly * 40 * 52 / 1000 # to thousands\n",
        "    # return f\"{min_annual:.0f}K-{max_annual:.0f}K\"\n",
        "\n",
        "  if '-' in salary:\n",
        "    min_salary, max_salary = salary.split('-')\n",
        "    min_salary = min_salary.replace('$', '').replace('K', '').strip()\n",
        "    max_salary = max_salary.replace('$', '').replace('K', '').strip()\n",
        "    try:\n",
        "      min_salary=int(float(min_salary))\n",
        "      max_salary=int(float(max_salary))\n",
        "      return f\"{min_salary}K-{max_salary}K\"\n",
        "    except ValueError:\n",
        "      return np.nan\n",
        "\n",
        "    # If no valid format is found, return NaN\n",
        "  return np.nan\n",
        "\n",
        "cleaned_df = pd.read_csv('glassdoor_jobs.csv')\n",
        "cleaned_df = cleaned_df.loc[:, ~cleaned_df.columns.str.contains('^Unnamed')]\n",
        "cleaned_df['Salary Estimate'] = cleaned_df['Salary Estimate'].apply(clean_salary)\n",
        "cleaned_df.dropna(subset=['Salary Estimate'], inplace=True)\n",
        "cleaned_df['Company Age'] = 2025 - cleaned_df['Founded']\n",
        "cleaned_df.drop('Founded', axis=1, inplace=True)\n",
        "\n",
        "# taking out the max and min salary from the range\n",
        "cleaned_df['Min_Salary'] = cleaned_df['Salary Estimate'].apply(lambda a: int(a.split('-')[0].replace('K', '')))\n",
        "cleaned_df['Min_Salary']\n",
        "cleaned_df['Max_Salary'] = cleaned_df['Salary Estimate'].apply(lambda a: int(a.split('-')[1].replace('K', '')))\n",
        "cleaned_df['Max_Salary']\n",
        "\n",
        "# avg sal\n",
        "cleaned_df['Average_Salary'] = (cleaned_df['Min_Salary'] + cleaned_df['Max_Salary']) / 2\n",
        "print(cleaned_df[['Salary Estimate', 'Min_Salary', 'Max_Salary', 'Average_Salary']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thUstOizK7GR"
      },
      "outputs": [],
      "source": [
        "print(cleaned_df)\n",
        "print(cleaned_df['Salary Estimate'].isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFUXGT6fK7GR"
      },
      "outputs": [],
      "source": [
        "cleaned_df['Job Title'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqpsopGAK7GR"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "- Extracted the minimum and maximum salary from the 'Salary Estimate' column.\n",
        "- Calculated the average salary.\n",
        "- Dropped the original 'Salary Estimate' column as it is no longer needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "# Chart 1: Distribution of Average Salary (Univariate)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(cleaned_df['Average_Salary'], kde=True, bins=30, color='blue')\n",
        "plt.title('Distribution of Average Salary')\n",
        "plt.xlabel('Average Salary (in thousands)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "This histogram plot shows the frequency of different average salaries for multiple job roles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "From the above histogram plot we can observe that as the average salary from $80K to $110k the frequency of the curve increase drastically and reaches highest around the range from `$85k to $94k` the peak is at the highest.\n",
        "\n",
        "- After the `$100k` mark the frequency of the curve decreases and almost converges with the x-axis from `$200k` onwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448CDAPjqfQr"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "#### Positive Impacts:\n",
        "\n",
        "- <b>Competitive Mid Range Salaries:</b> The distribution shows a strong concentration of salaries between _$75,000-$125,000_, suggesting the company is paying competitive market rates for most positions. This can help with employee retention and attraction of talent, reducing costly turnover.\n",
        "\n",
        "- <b>Room for Growth:</b> The extended right tail (showing salaries up to _$250,000_) demonstrates potential for career advancement and higher earnings, which can be a strong motivator for high-performing employees.\n",
        "\n",
        "#### Negative Impacts:\n",
        "\n",
        "- <b>Salary Compression:</b> The high concentration in the middle range might indicate salary compression, where experienced employees and new hires have similar salaries. This could lead to dissatisfaction among experienced employees and potentially leaving the company.\n",
        "  \n",
        "- <b>Wide Gap between Mid range and top earners:</b> The significant drop in frequency between the peak (_$100,000_) and higher salaries (_$200,000+_) might create perception issues about advancement opportunities, potentially causing mid-level talent to seek opportunities elsewhere."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Chart - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsttET9yK7GS"
      },
      "outputs": [],
      "source": [
        "# Chart 2: Distribution of Company Age (Univariate)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(cleaned_df['Company Age'], kde=True, bins=30, color='green')\n",
        "plt.title('Distribution of Company Age')\n",
        "plt.xlabel('Company Age (in years)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "top_jobs = cleaned_df['Job Title'].value_counts().nlargest(10).index\n",
        "sns.boxplot(x='Job Title', y='Average_Salary', data=cleaned_df[cleaned_df['Job Title'].isin(top_jobs)])\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Average Salary by Job Title')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dVpIINYklI"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": [
        "The boxplot effectively visualizes the distribution of average salaries across different job titles.\n",
        "- It provides clear summary of the distribution.\n",
        "- Easy to compare with other job titles along with their average salaries.\n",
        "- Able to detect outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmpgYnKYklI"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JiQyfWJYklI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo"
      },
      "source": [
        "#### Chart - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsAOLVyJK7GT"
      },
      "outputs": [],
      "source": [
        "# Chart 3: Count of Job Titles (Univariate)\n",
        "top_job_3 = cleaned_df['Job Title'].value_counts().nlargest(15).index\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.countplot(y='Job Title', data=cleaned_df[cleaned_df['Job Title'].isin(top_job_3)], palette='viridis', hue='Job Title', legend=False)\n",
        "plt.title('Count of Job Titles')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Job Title')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fge-S5ZAYoAp"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBItgRVYoAp"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85gYPyotYoAp"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jstXR6OYoAp"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoGjAbkUYoAp"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM"
      },
      "source": [
        "#### Chart - 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0SMPjw4K7GT"
      },
      "outputs": [],
      "source": [
        "# Chart 4: Average Salary by Job Title - (Bivariate)\n",
        "top_job_titles = cleaned_df['Job Title'].value_counts().nlargest(30).index\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.boxplot(x='Job Title', y='Average_Salary', hue='Job Title', legend=False, data=cleaned_df[cleaned_df['Job Title'].isin(top_job_titles)], palette='viridis')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Average Salary by Job Title')\n",
        "plt.xlabel('Job Titles (20)', fontsize=20)\n",
        "plt.ylabel('Average Salary (in thousands)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iky9q4vBYrdO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJRCwT6DYrdO"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6T5p64dYrdO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Ehk30pYrdP"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNxxz7MYrdP"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1"
      },
      "source": [
        "#### Chart - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "outputs": [],
      "source": [
        "# Chart 5: Average Salary by Company Size (Bivariate - Numerical:Categorical)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='Size', hue='Size', legend=False, y='Average_Salary', data=cleaned_df, palette='coolwarm')\n",
        "plt.title('Average Salary by Company Size')\n",
        "plt.xlabel('Company Size')\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Average Salary (in thousands)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcxuIMRPYuh3"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzvFGzlYuh3"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyqkiB8YYuh3"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpmQ266Yuh3"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM"
      },
      "source": [
        "#### Chart - 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "# Chart 6: Average Salary by Revenue - (Bivariate, Numerical:Categorical)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='Revenue', y='Average_Salary', hue='Revenue', legend=False, data=cleaned_df, palette='magma')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Average Salary by Revenue')\n",
        "plt.xlabel('Revenue')\n",
        "plt.ylabel('Average Salary (in thousands)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFf2-_FphqN"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loh7H2nzphqN"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouA3fa0phqN"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VECbqPI7phqN"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seke61FWphqN"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW4_bGpfphqN"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN"
      },
      "source": [
        "#### Chart - 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "# Chart 7: Average Salary by Location\n",
        "top_location = cleaned_df['Location'].value_counts().nlargest(25).index\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.boxplot(x='Location', y='Average_Salary', hue='Location', data=cleaned_df[cleaned_df['Location'].isin(top_location)], palette='plasma')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Average Salary by 25 Locations')\n",
        "plt.xlabel('Locations (25)')\n",
        "plt.ylabel('Average Salary (in thousands)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t27r6nlMphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv6ro40sphqO"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2jJGEOYphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po6ZPi4hphqO"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0JNsNcRphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSq8iUTphqO"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZR9WyysphqO"
      },
      "source": [
        "#### Chart - 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "outputs": [],
      "source": [
        "# Chart 8: Scatter Plot - Company Age vs. Average Salary\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Company Age', y='Average_Salary', data=cleaned_df, color='purple')\n",
        "plt.title('Company Age vs. Average Salary')\n",
        "plt.xlabel('Company Age (in years)')\n",
        "plt.ylabel('Average Salary (in thousands)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj7wYXLtphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob8u6rCTphqO"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZrbJ2SmphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZtgC_hjphqO"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFu4xreNphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey_0qi68phqO"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ55k-q6phqO"
      },
      "source": [
        "#### Chart - 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "outputs": [],
      "source": [
        "# B11: Company Size vs. Rating\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Size', y='Rating', data=cleaned_df, hue='Size', legend=False, palette='viridis')\n",
        "plt.title('Company Size vs. Rating')\n",
        "plt.xlabel('Company Size')\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Rating')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCFgpxoyphqP"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVxDimi2phqP"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVtJsKN_phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngGi97qjphqQ"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lssrdh5qphqQ"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBpY5ekJphqQ"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      },
      "source": [
        "#### Chart - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "outputs": [],
      "source": [
        "# Chart 10: Scatter Plot - Min_Salary vs. Max_Salary\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Min_Salary', y='Max_Salary', data=cleaned_df, color='orange')\n",
        "plt.title('Min_Salary vs. Max_Salary')\n",
        "plt.xlabel('Minimum Salary (in thousands)')\n",
        "plt.ylabel('Maximum Salary (in thousands)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M8mcRywphqQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8agQvks0phqQ"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgIPom80phqQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp13pnNzphqQ"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMzcOPDDphqR"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Ka1PC2phqR"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-EpHcCOp1ci"
      },
      "source": [
        "#### Chart - 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "outputs": [],
      "source": [
        "# B4: Average Salary by Industry\n",
        "plt.figure(figsize=(16, 6))\n",
        "sns.boxplot(x='Industry', y='Average_Salary', hue='Industry', legend=False, data=cleaned_df, palette='Set2')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Average Salary by Industry')\n",
        "plt.xlabel('Industry')\n",
        "plt.ylabel('Average Salary (in thousands)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_VqEhTip1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vsMzt_np1ck"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zGJKyg5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "druuKYZpp1ck"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3dbpmDWp1ck"
      },
      "source": [
        "#### Chart - 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "outputs": [],
      "source": [
        "def extract_seniority(job_title):\n",
        "    # Convert job_title to string to avoid AttributeError\n",
        "    job_title = str(job_title).lower()\n",
        "    if 'senior' in job_title or 'lead' in job_title or 'principal' in job_title or 'manager' in job_title:\n",
        "        return 'Senior'\n",
        "    elif 'jr' in job_title or 'junior' in job_title or 'entry level' in job_title:\n",
        "        return 'Junior'\n",
        "    else:\n",
        "        return 'Mid'  # Default to Mid-level\n",
        "\n",
        "cleaned_df['Seniority'] = cleaned_df['Job Title'].apply(extract_seniority)\n",
        "\n",
        "\n",
        "\n",
        "# B14: Seniority vs. Sector\n",
        "plt.figure(figsize=(16, 9))\n",
        "sns.countplot(x='Industry', hue='Seniority', data=cleaned_df, palette='Set2')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title('Seniority Count by Sector')\n",
        "plt.xlabel('Sector')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Seniority')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylSl6qgtp1ck"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2xqNkiQp1ck"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWILFDl5p1ck"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-lUsV2mp1ck"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7G43BXep1ck"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwDJXsLp1cl"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag9LCva-p1cl"
      },
      "source": [
        "#### Chart - 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "outputs": [],
      "source": [
        "# B10: Scatter Plot - Max_Salary vs. Rating\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Rating', y='Max_Salary', data=cleaned_df, color='red')\n",
        "plt.title('Max_Salary vs. Rating')\n",
        "plt.xlabel('Company Rating')\n",
        "plt.ylabel('Maximum Salary (in thousands)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6MkPsBcp1cl"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V22bRsFWp1cl"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cELzS2fp1cl"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MPXvC8up1cl"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL8l1tdLp1cl"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0"
      },
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "outputs": [],
      "source": [
        "# Select only numerical columns\n",
        "numerical_columns = cleaned_df.select_dtypes(include=['int64', 'float64']).columns\n",
        "numerical_df = cleaned_df[numerical_columns]\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr = numerical_df.corr()\n",
        "\n",
        "# Plot correlation heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap (Numerical Columns Only)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSqtnDqZNRR"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q29F0dvdveiT"
      },
      "source": [
        "#### Chart - 15 - Pair Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "outputs": [],
      "source": [
        "# Chart 11: Pair Plot for Numerical Features\n",
        "sns.pairplot(cleaned_df[['Min_Salary', 'Max_Salary', 'Average_Salary', 'Company Age', 'Rating']])\n",
        "plt.suptitle('Pair Plot for Numerical Features', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXh0U9oCveiU"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMmPjTByveiU"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22aHeOlLveiV"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPQ8RGwHveiV"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw"
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7MS06SUHkB-"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Hypothetical Statement - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "#### Statement 1: Job Title and Salary\n",
        "- Hypothesis: The average salary differs significantly across different job titles.\n",
        "  - Null Hypothesis (H_0): There is no significant difference in average salary across job titles.\n",
        "  - Alternative Hypothesis (H_1): There is a significant difference in average salary across job titles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Group the data by 'Job Title' and extract 'Avg_Salary'\n",
        "groups = [group['Average_Salary'].values for name, group in cleaned_df.groupby('Job Title')]\n",
        "\n",
        "# Perform ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(*groups)\n",
        "\n",
        "# Print results\n",
        "print(f\"ANOVA Results for Job Title vs. Avg_Salary:\")\n",
        "print(f\"F-statistic: {f_statistic:.2f}, p-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis as significant difference in average salary across job titles.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in average salary across job titles.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Hypothetical Statement - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "#### Statement 2: Sector and Company Rating\n",
        "\n",
        "- Statement: The \"Aerospace & Defense\" sector has a different distribution of company ratings compared to the \"Business Services\" sector.\n",
        "  - Null Hypothesis (H0): The distributions of company ratings are the same for the \"Aerospace & Defense\" and \"Business Services\" sectors.\n",
        "  - Alternative Hypothesis (H1): The distributions of company ratings are different for the \"Aerospace & Defense\" and \"Business Services\" sectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "aerospace_ratings = cleaned_df[cleaned_df['Sector'] == 'Aerospace & Defense']['Rating'].dropna()\n",
        "business_ratings = cleaned_df[cleaned_df['Sector'] == 'Business Services']['Rating'].dropna()\n",
        "\n",
        "# Perform the Mann-Whitney U test\n",
        "\n",
        "u_statistic, p_value_2 = stats.mannwhitneyu(aerospace_ratings, business_ratings, alternative='two-sided') #Non-parametric Test\n",
        "\n",
        "print(f\"Mann-Whitney U statistic: {u_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "if p_value_2 < alpha:\n",
        "    print(\"Reject the null hypothesis.\")\n",
        "    print(\"There is evidence to support that the distributions of company ratings are different for the Aerospace & Defense and Business Services sectors.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis.\")\n",
        "    print(\"There is no significant evidence to support that the distributions of company ratings are different for the Aerospace & Defense and Business Services sectors.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUvejAfpUZe"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "I have used Mann Whitney U statistical testing to obtain the P-value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd15vwWVpUZf"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOGYyiBpUZf"
      },
      "source": [
        "Mann Whitney U is a non-parametric test that doesn't assume normality but does assume that the data is at least ordinal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_IUdTipZyH"
      },
      "source": [
        "### Hypothetical Statement - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "#### Statement 3: Seniority and Average Salary\n",
        "\n",
        "Statement: Senior positions have a higher average salary than mid-level positions.\n",
        "- Null Hypothesis (H_0): There is no difference in average salary between senior and mid-level positions.\n",
        "- Alternative Hypothesis (H_1): The average salary of senior positions is greater than the average salary of mid-level positions. (One-tailed test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi815nCDK7Gd"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "senior_salaries = cleaned_df[cleaned_df['Seniority'] == 'Senior']['Average_Salary'].dropna()\n",
        "mid_salaries = cleaned_df[cleaned_df['Seniority'] == 'Mid']['Average_Salary'].dropna()\n",
        "\n",
        "levene_stat, levene_p = stats.levene(senior_salaries, mid_salaries)\n",
        "print(f\"Levene's test statistic: {levene_stat}, p-value: {levene_p}\")\n",
        "\n",
        "\n",
        "if levene_p < 0.05:\n",
        "    print(\"Variances are unequal, using Welch's t-test\")\n",
        "    t_statistic, p_value_3 = stats.ttest_ind(senior_salaries, mid_salaries, equal_var=False, alternative='greater')\n",
        "else:\n",
        "    t_statistic, p_value_3 = stats.ttest_ind(senior_salaries, mid_salaries, equal_var=True, alternative='greater')\n",
        "\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value_3}\")\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "if p_value_3 < alpha:\n",
        "    print(\"Reject the null hypothesis.\")\n",
        "    print(\"There is evidence to support that senior positions have a higher average salary than mid-level positions.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis.\")\n",
        "    print(\"There is no significant evidence to support that senior positions have a higher average salary than mid-level positions.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLW572S8pZyI"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWJ8v15pZyI"
      },
      "source": [
        "For statement 3 I have used ANOVA (Analysis of variance) to test if theres a significant difference in average salary across seniority in job titles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWbDXHzopZyI"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99G98V6pZyI"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyOF9F70UgQ"
      },
      "source": [
        "### 1. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "outputs": [],
      "source": [
        "cleaned_df.replace(\"-1\", np.nan, inplace=True)\n",
        "\n",
        "numerical_columns = cleaned_df.select_dtypes(include=['int64', 'float64']).columns\n",
        "cleaned_df[numerical_columns] = cleaned_df[numerical_columns].fillna(cleaned_df[numerical_columns].median())\n",
        "\n",
        "# categorical encoding with mode\n",
        "categorical_columns = cleaned_df.select_dtypes(include=['object']).columns\n",
        "cleaned_df[categorical_columns]= cleaned_df[categorical_columns].fillna(cleaned_df[categorical_columns].mode().iloc[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wuGOrhz0itI"
      },
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ixusLtI0pqI"
      },
      "source": [
        "In the dataset there were some places where the data had -1 in it, so I have replaced them with Nan.\n",
        "\n",
        "- After that those places where there numerical values in the column like the Revenue column, I have replaced them with median value\n",
        "- In place where categorical values like in Competitor, I have replaced missing values with their mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id1riN9m0vUs"
      },
      "source": [
        "### 2. Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3qXL5_RK7Ge"
      },
      "outputs": [],
      "source": [
        "# Handle outliers in 'Avg_Salary' using IQR\n",
        "Q1 = cleaned_df['Average_Salary'].quantile(0.25)\n",
        "Q3 = cleaned_df['Average_Salary'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "cleaned_df = cleaned_df[(cleaned_df['Average_Salary'] >= lower_bound) & (cleaned_df['Average_Salary'] <= upper_bound)]\n",
        "cleaned_df['Average_Salary']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578E2V7j08f6"
      },
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGZz5OrT1HH-"
      },
      "source": [
        "Used IQR (Interquartile Range) to detect and handle outliers, because it is a very robust method and works well with this type of datasets.\n",
        "- Works well for skewed dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 3. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "outputs": [],
      "source": [
        "# Encode your categorical columns\n",
        "# using One hot encoding\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_columns = ['Job Title', 'Location', 'Company Name', 'Size', 'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Headquarters', 'Competitors']\n",
        "for i in categorical_columns:\n",
        "  cleaned_df[i]= label_encoder.fit_transform(cleaned_df[i])\n",
        "\n",
        "cleaned_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67NQN5KX2AMe"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaue5h32n_G"
      },
      "source": [
        "I have used LabelEncoder from scikit-learn as a method of one hot encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwf50b-R2tYG"
      },
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMQiZwjn3iu7"
      },
      "source": [
        "#### 1. Expand Contraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr0sqGV0K7Ge"
      },
      "outputs": [],
      "source": [
        "%pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "outputs": [],
      "source": [
        "# Expand Contraction\n",
        "import contractions\n",
        "\n",
        "cleaned_df['Job Description'] = cleaned_df['Job Description'].apply(lambda x: contractions.fix(x))\n",
        "cleaned_df['Job Description']\n",
        "# basically if a sentence given is like : I'll be there within 6 min.\n",
        "# after contraction.fix() : I will be there within 6 min."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVIkgGqN3qsr"
      },
      "source": [
        "#### 2. Lower Casing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "outputs": [],
      "source": [
        "# Lower Casing\n",
        "cleaned_df['Job Description'] = cleaned_df['Job Description'].str.lower()\n",
        "cleaned_df['Job Description']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkPnILGE3zoT"
      },
      "source": [
        "#### 3. Removing Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "outputs": [],
      "source": [
        "# Remove Punctuations\n",
        "cleaned_df['Job Description'] = cleaned_df['Job Description'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "cleaned_df['Job Description']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlsf0x5436Go"
      },
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "outputs": [],
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "\n",
        "# for remvoing urls\n",
        "cleaned_df['Job Description'] = cleaned_df['Job Description'].apply(lambda a: re.sub(r'https\\S+|www\\S+|https\\S+', '', a, flags=re.MULTILINE))\n",
        "\n",
        "# digits removal\n",
        "cleaned_df['Job Description'] = cleaned_df['Job Description'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
        "\n",
        "# remove special word\n",
        "cleaned_df['Job Description'] = cleaned_df['Job Description'].apply(lambda b: re.sub(r'\\b(job|description)\\b', '', b))\n",
        "\n",
        "cleaned_df['Job Description']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT9DMSJo4nBL"
      },
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjcZpS_iK7Gf"
      },
      "outputs": [],
      "source": [
        "#%pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "outputs": [],
      "source": [
        "# Remove Stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words= set(stopwords.words('english'))\n",
        "cleaned_df['Job Description'] = cleaned_df['Job Description'].apply(lambda x: ' '.join(i for i in x.split() if i not in stop_words))\n",
        "cleaned_df['Job Description']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "outputs": [],
      "source": [
        "# Remove White spaces\n",
        "cleaned_df['Job Description'] = cleaned_df['Job Description'].apply(lambda x: ' '.join(x.split()))\n",
        "cleaned_df['Job Description']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c49ITxTc407N"
      },
      "source": [
        "#### 6. Rephrase Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r919hjqhK7Gf"
      },
      "outputs": [],
      "source": [
        "#%pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "outputs": [],
      "source": [
        "# Rephrase Text\n",
        "# from textblob import TextBlob\n",
        "# from multiprocessing import Pool, cpu_count\n",
        "# from spellchecker import SpellChecker\n",
        "\n",
        "# def rep_text(text):\n",
        "#   b = TextBlob(text)\n",
        "#   return str(b.correct())\n",
        "\n",
        "# spell = SpellChecker()\n",
        "\n",
        "# def correct_text(t):\n",
        "#   words= t.split()\n",
        "#   cor_word = [spell.correction(word) or word for word in words]\n",
        "#   return \" \".join(cor_word)\n",
        "\n",
        "# cleaned_df['Job Description'] = cleaned_df['Job Description'].apply(correct_text)\n",
        "\n",
        "# with Pool(cpu_count()) as pool:\n",
        "#   cleaned_df['Job Description'] = pool.map(rep_text, cleaned_df['Job Description'])\n",
        "\n",
        "\n",
        "# this part was taking way too much time, so commented out\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeJFEK0N496M"
      },
      "source": [
        "#### 7. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "cleaned_df['Job Description'] = cleaned_df['Job Description'].apply(word_tokenize)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ExmJH0g5HBk"
      },
      "source": [
        "#### 8. Text Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "outputs": [],
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemm = WordNetLemmatizer()\n",
        "\n",
        "cleaned_df['Stemmed_Description'] = cleaned_df['Job Description'].apply(lambda tk: [stemmer.stem(t) for t in tk])\n",
        "\n",
        "#lemmatization\n",
        "cleaned_df['Lemmatized_Description'] = cleaned_df['Job Description'].apply(lambda x: [lemm.lemmatize(i) for i in x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNqERVU536h"
      },
      "source": [
        "##### Which text normalization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9jKVxE06BC1"
      },
      "source": [
        "I have used PorterStemmer and WordNetLemmatizer from nltk library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGZvtmr3K7Gg"
      },
      "outputs": [],
      "source": [
        "cleaned_df['Stemmed_Description']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5UmGsbsOxih"
      },
      "source": [
        "#### 9. Part of speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "outputs": [],
      "source": [
        "# POS Taging\n",
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "cleaned_df['POS_tags'] = cleaned_df['Job Description'].apply(pos_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbL7jk8ZK7Gg"
      },
      "outputs": [],
      "source": [
        "cleaned_df['POS_tags']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      },
      "source": [
        "#### 10. Text Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "outputs": [],
      "source": [
        "# Vectorizing Text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "cleaned_df['Lemmatized_Text'] = cleaned_df['Lemmatized_Description'].apply(lambda tokens: ' '.join(tokens))\n",
        "cleaned_df['Lemmatized_Text']\n",
        "cleaned_df['Lemmatized_Description']\n",
        "# cleaned_df['Stemmed_Description']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4e3DuhVK7Gg"
      },
      "outputs": [],
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# tfidf_vector = TfidfVectorizer(max_features=1000)\n",
        "# tfidf_matrix = tfidf_vector.fit_transform(cleaned_df['Lemmatized_Text'])\n",
        "# tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vector.get_feature_names_out())\n",
        "# cleaned_df = pd.concat([cleaned_df, tfidf_df], axis=1)\n",
        "\n",
        "# # Drop the original 'Lemmatized_Description' column\n",
        "# cleaned_df.drop('Lemmatized_Description', axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBMux9mC6MCf"
      },
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su2EnbCh6UKQ"
      },
      "source": [
        "I have used TF-IDF (Term Frequency Inverse Document Frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 4. Feature Manipulation & Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C74aWNz2AliB"
      },
      "source": [
        "#### 1. Feature Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "outputs": [],
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "\n",
        "cleaned_df['Salary Range'] = cleaned_df['Max_Salary'] - cleaned_df['Min_Salary']\n",
        "\n",
        "# to reduce skewness\n",
        "cleaned_df['Log_avg_salary'] = np.log(cleaned_df['Average_Salary'] + 1)\n",
        "cleaned_df['Log_avg_salary']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0FoeJedK7Gh"
      },
      "outputs": [],
      "source": [
        "print(cleaned_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DejudWSA-a0"
      },
      "source": [
        "#### 2. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "outputs": [],
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "corr_target = numerical_df.corr()['Average_Salary'].abs().sort_values(ascending=False)\n",
        "imp_features = corr_target[1:5].index.tolist()\n",
        "print(corr_target)\n",
        "print(\"Top 10 features: \", imp_features)\n",
        "\n",
        "# cleaned_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEMng2IbBLp7"
      },
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      },
      "source": [
        "##### Which all features you found important and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgaEstsBnaf"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 5. Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqoHp30x9hH9"
      },
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqIkO1NaK7Gh"
      },
      "source": [
        "If any feature is highly skewed, we can apply transformations like Log Transform to reduce the skewness of the data, making it normally distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "outputs": [],
      "source": [
        "# Transform Your data\n",
        "skewed_features = ['Min_Salary', 'Max_Salary', 'Company Age', 'Average_Salary']\n",
        "for feature in skewed_features:\n",
        "  cleaned_df[f'Log_{feature}'] = np.log(cleaned_df[feature] + 1)\n",
        "\n",
        "cleaned_df['Company Age']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDnDkt2B6du"
      },
      "source": [
        "### 6. Data Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "outputs": [],
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "numerical_features = ['Rating', 'Salary Range', 'Log_avg_salary', 'Min_Salary', 'Max_Salary', 'Company Age', 'Log_Min_Salary', 'Log_Max_Salary', 'Log_Company Age']\n",
        "cleaned_df[numerical_features] = scaler.fit_transform(cleaned_df[numerical_features])\n",
        "cleaned_df[numerical_features]\n",
        "\n",
        "# X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
        "# X_test[numerical_features] = scaler.transform(X_test[numerical_features])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiVWRdJDDil"
      },
      "source": [
        "##### Which method have you used to scale you data and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UUpS68QDMuG"
      },
      "source": [
        "### 7. Dimesionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexQrXU-DjzY"
      },
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM71A2IqK7Gi"
      },
      "outputs": [],
      "source": [
        "cleaned_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5CmagL3EC8N"
      },
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKr75IDuEM7t"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 8. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "outputs": [],
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "to_drop = ['Job Description', 'Stemmed_Description', 'Lemmatized_Description', 'POS_tags', 'Lemmatized_Text', 'Seniority', 'Salary Estimate']\n",
        "cleaned_df = cleaned_df.drop(columns=to_drop)\n",
        "X = cleaned_df.drop(['Average_Salary', 'Min_Salary', 'Max_Salary'], axis=1)\n",
        "y = cleaned_df['Average_Salary']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set shape: \", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape: \", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYVBYqtLK7Gi"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jOshJ_qK7Gi"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKvONjwE8ra"
      },
      "source": [
        "##### What data splitting ratio have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      },
      "source": [
        "I have used the default 80 20 ratio to split the data into training and testing sets respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFXCmaRdK7Gi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1XJ9OREExlT"
      },
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOzZv6IFROw"
      },
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeKDIv7pFgcC"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q8njQFEK7Gi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compute correlation matrix\n",
        "correlation_matrix = numerical_df.corr()\n",
        "\n",
        "# Display correlation with target variable ('Avg_Salary')\n",
        "correlation_with_target = correlation_matrix['Average_Salary'].abs().sort_values(ascending=False)\n",
        "print(\"Correlation with Avg_Salary:\")\n",
        "print(correlation_with_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "outputs": [],
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# smote = SMOTE(random_state=42)\n",
        "# X_train_resampled, y_train_resampled =smote.fit_resample(X_train, y_train)\n",
        "# print(\"Resampled training set shape: \", X_train_resampled.shape)\n",
        "# print(X_train_resampled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIqpNgepFxVj"
      },
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbet1HwdGDTz"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-llTwavNK7Gj"
      },
      "source": [
        "#### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "# Fit the Algorithm\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "y_pred_linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJBuiUVfxKd"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "print(\"Linear Regression - MSE: \", mse_linear)\n",
        "print(\"Linear Regressiond - R2 Score\", r2_linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qY1EAkEfxKe"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PsXLa-pK7Gj"
      },
      "outputs": [],
      "source": [
        "# Calculate residuals\n",
        "residuals_linear = y_test - y_pred_linear\n",
        "\n",
        "# Plot residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred_linear, residuals_linear, alpha=0.5)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Predicted Salary')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Linear Regression: Residual Plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEA_iYGFK7Gj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x=y_test, y=y_pred_linear, alpha=0.6, color='blue', label=\"Predicted vs Actual\")\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='dashed', linewidth=2, label=\"Perfect Fit\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Linear Regression: Actual vs Predicted\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# Fit the Algorithm\n",
        "cv_sc = cross_val_score(linear_model, X_train, y_train, cv=5, scoring='r2')\n",
        "print(\"Linear Regression - Cross Val r2 scores: \", cv_sc)\n",
        "print(\"Linear Regression - Mean Cross Val r2 score: \", cv_sc.mean())\n",
        "# Predict on the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3sJfHi5K7Gj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, 6), cv_sc, marker='o', linestyle='-', color='blue')\n",
        "\n",
        "\n",
        "plt.xlabel(\"Fold Number\")\n",
        "plt.ylabel(\"R^2 Score\")\n",
        "plt.title(\"Cross-Validation R^2 Scores Across Folds\")\n",
        "plt.xticks(range(1, 6))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "negyGRa7fxKf"
      },
      "source": [
        "Linear Regression has no hyperparameters to tune. But I have used cross validation score from scikit learn and applied 5 folds cross validation.\n",
        "\n",
        "The model performs well overall, with R^2 scores around 0.968 to 0.976 (close to 1, indicating a strong fit).\n",
        "There's some variation in scores across folds:\n",
        "- The lowest score is around 0.968 (Fold 2).\n",
        "- The highest score is about 0.976 (Fold 3).\n",
        "- This means the model performs slightly worse in some splits but remains consistent overall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfvqoZmBfxKf"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaLui8CcfxKf"
      },
      "source": [
        "The actual vs predicted graph is showing a perfect graph of linear regreesion that fits our dataset without any underfitting or overfitting!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGIKtCsvK7Gk"
      },
      "source": [
        "#### Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CchT3YT2K7Gk"
      },
      "outputs": [],
      "source": [
        "# ML Model - 2\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Fit the Algorithm\n",
        "randForest = RandomForestRegressor(random_state=40)\n",
        "randForest.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "y_pred_RF = randForest.predict(X_test)\n",
        "y_pred_RF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS98CYPTK7Gk"
      },
      "source": [
        "#### It's an ensemble model that combines multiple decision trees to improve prediction accuracy and reduce overfitting.\n",
        "\n",
        "- #### It is robust to outliers and can handle non-linear relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYfwnehpsJ1"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "mse_RF = mean_squared_error(y_test, y_pred_RF)\n",
        "r2_RF = r2_score(y_test, y_pred_RF)\n",
        "print('Random Forest - MSE: ', mse_RF)\n",
        "print(\"Random Forest - R2 Score: \", r2_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUpmiNJSK7Gk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=y_test, y=y_pred_RF, color='blue', alpha=0.6, label=\"Predicted vs Actual\")\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='dashed', linewidth=2, label=\"Perfect Fit\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Random Forest Regression: Actual vs. Predicted\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF3dkn1aK7Gk"
      },
      "outputs": [],
      "source": [
        "# Calculate residuals\n",
        "residuals_rf = y_test - y_pred_RF\n",
        "\n",
        "# Plot residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred_RF, residuals_rf, alpha=0.5)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Predicted Salary')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Random Forest: Residual Plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGVf57hxK7Gk"
      },
      "outputs": [],
      "source": [
        "# Get feature importances\n",
        "importances_rf = randForest.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(feature_names, importances_rf, color='skyblue')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Random Forest: Feature Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "outputs": [],
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "cv_scores_rf = cross_val_score(randForest, X_train, y_train, cv=5, scoring='r2')\n",
        "print(\"Random Forest - Cross-Validation R2 Scores:\", cv_scores_rf)\n",
        "print(\"Random Forest - Mean Cross-Validation R2 Score:\", cv_scores_rf.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLGNLWGbK7Gk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(randForest, param_grid_rf, cv=5, scoring='r2')\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "print(\"Random Forest - Best Parameters:\", grid_search_rf.best_params_)\n",
        "y_pred_rf_tuned = grid_search_rf.predict(X_test)\n",
        "mse_rf_tuned = mean_squared_error(y_test, y_pred_rf_tuned)\n",
        "r2_rf_tuned = r2_score(y_test, y_pred_rf_tuned)\n",
        "print(\"Random Forest (Tuned) - Mean Squared Error:\", mse_rf_tuned)\n",
        "print(\"Random Forest (Tuned) - R2 Score:\", r2_rf_tuned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAih1iBOpsJ2"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      },
      "source": [
        "For random forest I have used GridSearch Cross Validation from scikit learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74yRdG6UpsJ3"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fze-IPXLpx6K"
      },
      "source": [
        "### ML Model - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuM_GHGkK7Gl"
      },
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCddEzv5K7Gl"
      },
      "outputs": [],
      "source": [
        "#%pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation\n",
        "from xgboost import XGBRegressor\n",
        "# Fit the Algorithm\n",
        "xgb_model = XGBRegressor(random_state=40)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "y_pred_xgb\n",
        "# Predict on the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1Njj-A_K7Gl"
      },
      "outputs": [],
      "source": [
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "print(\"XGBoost - Mean Squared Error: \", mse_xgb)\n",
        "print(\"XGBoost - R2 Score: \", r2_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AN1z2sKpx6M"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_xgb, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)  # Diagonal line\n",
        "plt.xlabel('Actual Salary')\n",
        "plt.ylabel('Predicted Salary')\n",
        "plt.title('XGBoost: Actual vs. Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUOhq4DEK7Gl"
      },
      "outputs": [],
      "source": [
        "# Calculate residuals\n",
        "residuals_xgb = y_test - y_pred_xgb\n",
        "\n",
        "# Plot residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred_xgb, residuals_xgb, alpha=0.5)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Predicted Salary')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('XGBoost: Residual Plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n72ZxPudK7Gl"
      },
      "outputs": [],
      "source": [
        "\n",
        "importances_xgb = xgb_model.feature_importances_\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(feature_names, importances_xgb, color='lightgreen')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('XGBoost: Feature Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PIHJqyupx6M"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "cv_scores_xgb = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='r2')\n",
        "print(\"XGBoost - Cross-Validation R2 Scores:\", cv_scores_xgb)\n",
        "print(\"XGBoost - Mean Cross-Validation R2 Score:\", cv_scores_xgb.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvHJDHJjK7Gl"
      },
      "outputs": [],
      "source": [
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=5, scoring='r2')\n",
        "\n",
        "# Fit the model\n",
        "grid_search_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"XGBoost - Best Parameters:\", grid_search_xgb.best_params_)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "y_pred_xgb_tuned = grid_search_xgb.predict(X_test)\n",
        "mse_xgb_tuned = mean_squared_error(y_test, y_pred_xgb_tuned)\n",
        "r2_xgb_tuned = r2_score(y_test, y_pred_xgb_tuned)\n",
        "print(\"XGBoost (Tuned) - Mean Squared Error:\", mse_xgb_tuned)\n",
        "print(\"XGBoost (Tuned) - R2 Score:\", r2_xgb_tuned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-qAgymDpx6N"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQMffxkwpx6N"
      },
      "source": [
        "I have used GridSearchCV as hyperparameter optimization for the XGBoost model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hykwinpx6N"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzVzZC6opx6N"
      },
      "source": [
        "Previously the Mean Squared Error:  0.342832715\n",
        "\n",
        "After using GridSearchCV the MSE came down to : 0.16411464\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CCil-SKHpo"
      },
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVz9hHDKFms"
      },
      "source": [
        "For all of the three models I have used Mean Squared Error and R2 Score for evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFFvTBNJzUa"
      },
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGl1hHyA_VK"
      },
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvVTiIxBL-C"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyNgTHvd2WFk"
      },
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5McJBi2d8v"
      },
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "outputs": [],
      "source": [
        "# Save the File\n",
        "import joblib\n",
        "\n",
        "best_model = grid_search_xgb.best_estimator_\n",
        "joblib.dump(best_model, 'best_xgb_model.pkl')\n",
        "print(\"Best Model saved : \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      },
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "outputs": [],
      "source": [
        "# Load the File and predict unseen data.\n",
        "loadedModel = joblib.load('best_xgb_model.pkl')\n",
        "print(\"model loaded successfully! \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUAxG0SwK7Gm"
      },
      "outputs": [],
      "source": [
        "y_pred_test = loadedModel.predict(X_test)\n",
        "X_test['Predicted Salary'] = y_pred_test\n",
        "print(X_test[['Predicted Salary']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFx6MVaUK7Gm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "print('MSE on test data: ', mse_test)\n",
        "print('R2 score on test data', r2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sZ3wZDLK7Gm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot actual vs. predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_test, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)  # Diagonal line\n",
        "plt.xlabel('Actual Salary')\n",
        "plt.ylabel('Predicted Salary')\n",
        "plt.title('XGBoost: Actual vs. Predicted (Test Data)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76EBvjJMK7Gm"
      },
      "outputs": [],
      "source": [
        "# Calculate residuals\n",
        "residuals_test = y_test - y_pred_test\n",
        "\n",
        "# Plot residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred_test, residuals_test, alpha=0.5)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Predicted Salary')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('XGBoost: Residual Plot (Test Data)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kee-DAl2viO"
      },
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "Write the conclusion here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIfDvo9L0UH2"
      },
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}