{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souraOP/Projects-Labmentix/blob/main/Amazon%20Prime%20EDA/Sample_ML_Submission_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Amazon Prime Video ML\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1** - Sourasish Mondal"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[https://github.com/souraOP/Projects-Labmentix/tree/main/Amazon%20Prime%20EDA](https://github.com/souraOP/Projects-Labmentix/tree/main/Amazon%20Prime%20EDA)"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import ast\n",
        "import scipy.stats as stats\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, PowerTransformer\n",
        "from sklearn.feature_selection import VarianceThreshold, mutual_info_regression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "url1 = 'https://raw.githubusercontent.com/souraOP/Projects-Labmentix/refs/heads/main/Amazon%20Prime%20EDA/credits.csv'\n",
        "url2 = \"https://raw.githubusercontent.com/souraOP/Projects-Labmentix/refs/heads/main/Amazon%20Prime%20EDA/titles.csv\"\n",
        "\n",
        "cred_df =pd.read_csv(url1)\n",
        "title_df=pd.read_csv(url2)"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = cred_df.merge(title_df, on='id', how='left')"
      ],
      "metadata": {
        "id": "rBslE0AZ6fLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df_merged.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df_merged.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df_merged.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df_merged.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df_merged.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df_merged.isnull(), cmap=\"crest\")\n",
        "plt.show()\n",
        "print(\"The uniform colour of the heatmap indicates that there are NO missing values\")"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After merging the credits and titles datasets:\n",
        "\n",
        "1. Dataset Rows and Columns\n",
        "Total Rows: 124,235\n",
        "Total Columns: 19\n",
        "\n",
        "2. Key Columns\n",
        "- Movie/Show Information: id, title, type, release_year, genres, runtime, description\n",
        "\n",
        "- Cast & Crew Details: name, character, role (e.g., ACTOR, DIRECTOR) Performance Metrics: imdb_score, imdb_votes, tmdb_score, tmdb_popularity\n",
        "\n",
        "3. Duplicates: 168 duplicate rows.\n",
        "\n",
        "Missing Values: Several columns have missing values, including: character (16,307 missing) age_certification (67,640 missing) seasons (116,194 missing, likely because most entries are movies) imdb_score & tmdb_score (missing values in rating data)\n",
        "\n",
        "4. Initial Observations\n",
        "\n",
        "Movies vs. Shows: The dataset contains both movies and TV shows (type column).\n",
        "\n",
        "Genre Distribution: Titles belong to multiple genres, stored in a list format.\n",
        "\n",
        "Popular Roles: ACTOR and DIRECTOR are the most common roles.\n",
        "\n",
        "Ratings & Popularity: imdb_score, imdb_votes, and tmdb_score help evaluate performance."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df_merged.shape[1]"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df_merged.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- title: Name of the movie or TV show String\n",
        "\n",
        "- type: Type of content (MOVIE or SHOW) String\n",
        "\n",
        "- id Unique: identifier for a movie or TV show String\n",
        "\n",
        "- person_id: Unique identifier for a cast or crew member Integer\n",
        "\n",
        "- description: Brief synopsis of the title String (Can be Null)\n",
        "\n",
        "- release_year: Year the movie or show was released Integer\n",
        "\n",
        "- age_certification Age rating (e.g., PG, R, TV-MA) String (Can be Null)\n",
        "\n",
        "- runtime: Duration in minutes Integer\n",
        "\n",
        "- genres: List of genres (e.g., Action, Comedy, Drama) String (stored as list format)\n",
        "\n",
        "- production_countries: Countries where the movie/show was produced (stored as a list) String\n",
        "\n",
        "- seasons: Number of seasons (only for TV shows, missing for movies) Integer\n",
        "\n",
        "- imdb_id: IMDb identifier for the title String\n",
        "\n",
        "- imdb_score: IMDb rating (scale of 1-10) Float\n",
        "\n",
        "- imdb_votes: Number of votes received on IMDb Integer\n",
        "\n",
        "- tmdb_popularity: Popularity score from TMDb (higher means more popular) Float\n",
        "\n",
        "- tmdb_score: TMDb rating (scale of 1-10) Float"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df_merged.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "# Remove Duplicate Rows\n",
        "df_merged = df_merged.drop_duplicates()\n",
        "\n",
        "# handle Missing Values\n",
        "df_merged['character'] = df_merged['character'].fillna(\"Unknown\")\n",
        "df_merged['description'] = df_merged['description'].fillna(\"No description available\")\n",
        "df_merged['age_certification'] = df_merged['age_certification'].fillna(\"Unrated\")\n",
        "\n",
        "df_merged['seasons'] = df_merged['seasons'].fillna(0)  # TV shows only\n",
        "df_merged['imdb_score'] = df_merged['imdb_score'].fillna(df_merged['imdb_score'].median())\n",
        "df_merged['imdb_votes'] = df_merged['imdb_votes'].fillna(0)\n",
        "df_merged['tmdb_score'] = df_merged['tmdb_score'].fillna(df_merged['tmdb_score'].median())\n",
        "df_merged['tmdb_popularity'] = df_merged['tmdb_popularity'].fillna(0)\n",
        "\n",
        "\n",
        "def convert_to_list(value):\n",
        "  try:\n",
        "    return ast.literal_eval(value) if isinstance(value, str) else value\n",
        "  except:\n",
        "    return []\n",
        "\n",
        "df_merged['genres'] = df_merged['genres'].apply(convert_to_list)\n",
        "df_merged['production_countries'] = df_merged['production_countries'].apply(convert_to_list)\n",
        "\n",
        "\n",
        "df_merged['release_year'] = df_merged['release_year'].astype(int)\n",
        "df_merged['runtime'] = df_merged['runtime'].astype(int)\n",
        "df_merged['seasons'] = df_merged['seasons'].astype(int)\n",
        "df_merged['imdb_votes'] = df_merged['imdb_votes'].astype(int)\n",
        "df_merged['tmdb_popularity'] = df_merged['tmdb_popularity'].astype(float)\n",
        "df_merged.info(), df_merged.head()\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removed 168 duplicate rows, reducing the dataset to 124,179 rows. Handled missing values:\n",
        "\n",
        "Filled character with \"Unknown\" for actors. Replaced missing description with \"No description available\".\n",
        "\n",
        "Set age_certification as \"Unrated\" for missing values.\n",
        "\n",
        "Set seasons to 0 for movies.\n",
        "\n",
        "Filled missing imdb_score and tmdb_score with their median values. Set missing imdb_votes and tmdb_popularity to 0.\n",
        "\n",
        "Converted genres and production_countries to list format for better analysis. Standardized data types (e.g., release_year, runtime, imdb_votes as integers)."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df_merged, x=\"type\", hue='type', palette=\"husl\", legend=False)\n",
        "plt.title(\"Distribution of Movies vs. Shows\")\n",
        "plt.xlabel(\"Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This countplot helps understand whether the dataset is dominated by movies or TV shows."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Movies are very much in number than shows"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive:** If the platform wants to invest in content, focusing on movies may cater to a larger audience.\n",
        "\n",
        "**Negative:** Underinvestment in TV shows could lead to losing long-term subscribers who prefer series over movies."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df_merged[\"release_year\"], bins=50, kde=True, color=\"green\")\n",
        "plt.title(\"Movies & Shows Released Over the Years\")\n",
        "plt.xlabel(\"Release Year\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helps us understand how content production has evolved over time."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A surge in releases during the 2010s, but a decline after 2020. Probaly due to Covid-19 Pandemic."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: Identifies golden periods for content creation and industry growth.\n",
        "\n",
        "- Negative: The decline post-2020 could indicate a potential market saturation or impact of streaming service competition."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df_merged[\"imdb_score\"], bins=30, kde=True, color=\"blue\")\n",
        "plt.title(\"Distribution of IMDb Scores\")\n",
        "plt.xlabel(\"IMDb Score\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "histplot examines the quality perception of the content."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most content has IMDb ratings between 5-7."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: High engagement expected for well-rated content, driving better recommendations.\n",
        "\n",
        "- Negative: A large volume of mid-rated content could indicate a lack of exceptional titles that drive strong engagement."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_merged[\"tmdb_score\"], bins=60, kde=True, color=\"red\")\n",
        "plt.title(\"Distribution of TMDb Scores\")\n",
        "plt.xlabel(\"TMDb Score\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This histplot of the distribution of TMDB scores is similar to IMDb scores but focused on audience-driven ratings"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scores mostly range from 5-7, similar to IMDb, confirming consistency."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: Consistent ratings across platforms indicate reliable audience feedback.\n",
        "\n",
        "- Negative: If most content is rated similarly, it might indicate a lack of differentiation in quality."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "from collections import Counter\n",
        "\n",
        "all_genres = [genre for sublist in df_merged['genres'] for genre in sublist]\n",
        "genre_counts = Counter(all_genres).most_common(10)\n",
        "genres, counts = zip(*genre_counts)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=list(genres), y=list(counts), hue=list(genres), palette=\"coolwarm\")\n",
        "plt.title(\"Top 10 Most Common Genres\")\n",
        "plt.xlabel(\"Genres\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Barplot identifies audience preferences based on the most frequent genres."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drama, Comedy, and Action are the most dominant genres."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: Streaming services can prioritize these genres for production and licensing deals.\n",
        "\n",
        "- Negative: Over-saturation of these genres could limit diversity, making niche audiences feel neglected."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df_merged[\"runtime\"], bins=50, kde=True, color=\"grey\")\n",
        "plt.title(\"Runtime Distribution for Movies & Shows\")\n",
        "plt.xlabel(\"Runtime (Minutes)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determines ideal content length preferences."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most movies are between 80-120 minutes; TV shows vary widely."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: Helps optimize recommendations based on viewer behavior (e.g., short vs. long movies).\n",
        "\n",
        "- Negative: Over-focusing on one runtime range may miss audiences preferring shorter/longer content."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_merged, x=\"runtime\", y=\"imdb_score\", alpha=0.5, color=\"blue\")\n",
        "plt.title(\"IMDb Score vs. Runtime\")\n",
        "plt.xlabel(\"Runtime (Minutes)\")\n",
        "plt.ylabel(\"IMDb Score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scatterplot tests if longer movies/shows get better ratings."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No clear pattern; runtime does not significantly impact ratings."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: Platforms can confidently recommend shorter movies without fearing lower ratings.\n",
        "\n",
        "- Negative: If specific runtime ranges had higher ratings, missing this insight could lead to poor content selection."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "top_actors = df_merged[df_merged[\"role\"] == \"ACTOR\"][\"name\"].value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_actors.values, y=top_actors.index, hue=top_actors.values, palette=\"pastel\")\n",
        "plt.title(\"Top 10 Most Frequent Actors\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Actor Name\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifies which actors appear most often."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some actors dominate content, meaning they are likely popular."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: Helps in marketing by promoting familiar faces that drive engagement.\n",
        "\n",
        "- Negative: Over-reliance on the same actors could limit audience diversity."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "top_directors = df_merged[df_merged[\"role\"] == \"DIRECTOR\"][\"name\"].value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.barplot(x=top_directors.values, y=top_directors.index, hue=top_directors.values, palette=\"magma\")\n",
        "plt.title(\"Top 10 Most Frequent Directors\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Director Name\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifies influential filmmakers."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some directors contribute significantly to the dataset."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: Can influence content acquisition strategies by prioritizing top directors' films.\n",
        "\n",
        "- Negative: Over-prioritizing famous directors might overlook emerging talents.\n",
        "\n"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_merged, x=\"imdb_score\", y=\"tmdb_score\", alpha=0.5, color=\"green\")\n",
        "plt.title(\"IMDb Score vs. TMDb Score\")\n",
        "plt.xlabel(\"IMDb Score\")\n",
        "plt.ylabel(\"TMDb Score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluates if both rating systems align."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A positive correlation shows that high IMDb scores also tend to have high TMDb scores, meaning that the audience and the critics have a similar mindset."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: Enables platforms to use one rating system as a proxy for another in recommendations.\n",
        "\n",
        "- Negative: If the correlation were weak, relying on only one metric could mislead content strategy."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "all_countries = [country for sublist in df_merged['production_countries'] for country in sublist]\n",
        "country_counts = Counter(all_countries).most_common(10)\n",
        "countries, counts = zip(*country_counts)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.lineplot(x=list(countries), y=list(counts))\n",
        "plt.title(\"Top 10 Production Countries\")\n",
        "plt.xlabel(\"Country\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=50)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifies which countries contribute most to content production."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "USA, UK, Canada, and India lead content creation."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: Platforms can target licensing deals and marketing efforts in these key regions.\n",
        "\n",
        "- Negative: Heavy reliance on a few countries may ignore emerging markets with untapped content opportunities."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_merged, x=\"release_year\", y=\"tmdb_popularity\", color=\"darkgreen\")\n",
        "plt.title(\"TMDb Trend Over Time\")\n",
        "plt.xlabel(\"Release Year\")\n",
        "plt.ylabel(\"TMDb Popularity\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lineplot identifies whether recent content is more popular."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Popularity has increased over time, with peaks in recent years."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: Suggests that newer content attracts more engagement, supporting fresh content investments.\n",
        "\n",
        "- Negative: Older content might be undervalued despite having a loyal audience."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "def imdb_vs_tmdb(df):\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  sns.scatterplot(x=df['imdb_score'], y=df['tmdb_score'], alpha=0.5, color='green', label='IMDb vs TMDB')\n",
        "  sns.scatterplot(x=df['tmdb_score'], y=df['imdb_score'], alpha=0.5,\n",
        "  color='red', label='TMDB vs IMDb')\n",
        "  plt.title(\"IMDb vs TMDB Score\")\n",
        "  plt.xlabel(\"IMDb Score\")\n",
        "  plt.ylabel(\"TMDB Score\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "imdb_vs_tmdb(df_merged)"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determines the imdb score and tmdb score"
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most content is rated 5 and 6"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Positive: Helps platforms cater to their dominant audience (teens & adults).\n",
        "\n",
        "- Negative: If children’s content is underrepresented, family-friendly subscription growth may suffer."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "plt.figure(figsize=(13, 7))\n",
        "corr_matrix = df_merged.corr(numeric_only=True)\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"crest\", linewidths=0.5, fmt=\".2f\")\n",
        "plt.title(\"Correlation Heatmap of Numerical Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A correlation heatmap visually represents relationships between numerical variables in the dataset.\n",
        "\n",
        "It helps identify:\n",
        "\n",
        "- Strongly correlated variables, which can aid in feature selection for machine learning.\n",
        "\n",
        "- Weak or negative correlations, which can indicate independent factors.\n",
        "\n",
        "- Redundant variables that do not contribute new information.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDb Score vs. TMDb Score (Strong Positive Correlation)\n",
        "\n",
        "Insight: If a movie is highly rated on IMDb, it is also likely to have a high TMDb rating."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "numeric_columns = [\"release_year\", \"runtime\", \"imdb_score\", \"imdb_votes\", \"tmdb_popularity\", \"tmdb_score\"]\n",
        "sns.pairplot(df_merged[numeric_columns])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pair plot is a powerful visualization tool that helps analyze relationships between multiple numerical variables in a dataset. It generates scatter plots for each pair of variables and histograms for individual variables along the diagonal. This allows us to:\n",
        "\n",
        "- Identify Correlations – Check if certain variables have strong positive or negative relationships.\n",
        "\n",
        "- Detect Outliers – Spot any extreme values that might require further investigation. Understand Distributions – Examine how each numerical variable is spread."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Relationship Between IMDb Score & IMDb Votes We expect a positive correlation: Movies with higher IMDb votes tend to have higher IMDb scores because more popular films generally attract both audience engagement and favorable reviews. However, we might see some low-rated movies with high votes, indicating polarizing films that received significant attention.\n",
        "\n",
        "- IMDb Score vs. TMDb Score A strong positive correlation is expected between these two variables since both IMDb and TMDb are movie-rating platforms. Any discrepancies (e.g., a high IMDb score but a low TMDb score) could indicate different audience demographics between the platforms."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H_0): There is no correlation between runtime and IMDb scores.\n",
        "\n",
        "Alternative Hypothesis (H_1): There is a positive correlation between runtime and IMDb scores."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "df_merged = df_merged.dropna(subset=['runtime'])\n",
        "\n",
        "# Perform Pearson correlation test\n",
        "correlation, p_value = stats.pearsonr(df_merged['runtime'], df_merged['imdb_score'])\n",
        "\n",
        "# Print results\n",
        "print(\"\\nHypothesis 2: Runtime vs. IMDb Score Correlation\")\n",
        "print(f\"Pearson Correlation: {correlation:.4f}, P-Value: {p_value:.4f}\")\n",
        "if p_value < 0.05:\n",
        "    print(\"Result: Reject the Null Hypothesis (Significant correlation between runtime and IMDb scores)\")\n",
        "else:\n",
        "    print(\"Result: Fail to Reject the Null Hypothesis (No significant correlation)\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson correlation test"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check linear relationship between two numerical variables"
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H₀): The mean IMDb score across all titles is ≤ 7.0.\n",
        "\n",
        "Alternative Hypothesis (H₁): The mean IMDb score across all titles is greater than 7.0."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "t_stat, p_value = stats.ttest_1samp(df_merged['imdb_score'], 7.0)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nHypothesis 3: Average IMDb Score > 7.0\")\n",
        "print(f\"T-Statistic: {t_stat:.4f}, P-Value: {p_value:.4f}\")\n",
        "if p_value < 0.05 and t_stat > 0:\n",
        "    print(\"Result: Reject the Null Hypothesis (Average IMDb score is significantly greater than 7)\")\n",
        "else:\n",
        "    print(\"Result: Fail to Reject the Null Hypothesis (No significant evidence that the average IMDb score is above 7)\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Sample t-test"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check if the mean of a sample is significantly different from a given value"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing Values:\\n\", df_merged.isnull().sum())"
      ],
      "metadata": {
        "id": "DQVJOpVXNutC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Handle missing and NaN values\n",
        "df_merged.fillna({\n",
        "    'description': 'No description available',\n",
        "    'age_certification': 'Not Rated',\n",
        "    'seasons': 0,\n",
        "    'imdb_score': df_merged['imdb_score'].median(),\n",
        "    'imdb_votes': 0,\n",
        "    'tmdb_popularity': df_merged['tmdb_popularity'].median(),\n",
        "    'tmdb_score': df_merged['tmdb_score'].median(),\n",
        "    'person_id': -1,\n",
        "    'name': 'Unknown',\n",
        "    'character': 'Unknown',\n",
        "    'role': 'Unknown'\n",
        "}, inplace=True)\n",
        "\n",
        "missing_values_summary = df_merged.isnull().sum()\n",
        "missing_values_summary\n",
        "missing_values = df_merged.isnull().sum()\n",
        "print(\"Missing Values in Each Column:\\n\", missing_values[missing_values > 0])\n",
        "\n",
        "# Handling numerical NaN values using median imputation\n",
        "numerical_cols = df_merged.select_dtypes(include=['int64', 'float64']).columns\n",
        "for col in numerical_cols:\n",
        "  df_merged.loc[:, col] = df_merged[col].fillna(df_merged[col].median())\n",
        "\n",
        "# Handling categorical NaN values using mode imputation\n",
        "categorical_cols = df_merged.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "  # Check if mode is a list and take the first element if it is\n",
        "  mode_value = df_merged[col].mode()\n",
        "\n",
        "  # Check if mode is a Series and take the first value if it is non-empty\n",
        "  if isinstance(mode_value, pd.Series) and not mode_value.empty:\n",
        "      mode_value = mode_value.iloc[0]\n",
        "  # Check if mode is a list or numpy array and take the first value if non-empty\n",
        "  elif isinstance(mode_value, (list, np.ndarray)) and len(mode_value) > 0:\n",
        "      mode_value = mode_value[0]\n",
        "  else:\n",
        "      mode_value = \"Unknown\"  # Fallback to a default value if mode is empty\n",
        "\n",
        "  # Ensure mode_value is a scalar or dictionary for fillna\n",
        "  if isinstance(mode_value, (list, np.ndarray)):\n",
        "      mode_value = mode_value[0] if len(mode_value) > 0 else \"Unknown\"  # Handle cases where mode returns a list\n",
        "\n",
        "  df_merged.loc[:, col] = df_merged[col].fillna(mode_value)\n",
        "\n",
        "print(\"Missing Values After Handling:\\n\", df_merged.isnull().sum())"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used different techniques based on the data type and context of the missing values to ensure minimal data distortion. Here's a breakdown:\n",
        "\n",
        "- Categorical Columns (e.g., age_certification, character, role)\n",
        "Technique Used: Mode Imputation (Filling with \"Unknown\")\n",
        "\n",
        "Reason: Since categorical values don't have a numerical relationship, replacing missing values with \"Unknown\" prevents loss of data while keeping the dataset intact. Helps avoid introducing bias by assuming a specific category.\n",
        "\n",
        "- Numerical Columns (e.g., runtime, imdb_score, imdb_votes, tmdb_popularity, tmdb_score)\n",
        "Technique Used: Median Imputation\n",
        "\n",
        "Reason: The median is robust to outliers compared to the mean. Movie ratings, votes, and popularity scores often have skewed distributions, making median imputation a better choice than mean imputation.\n",
        "\n",
        "- List-Type Columns (genres, production_countries)\n",
        "Technique Used: Replacing Missing Values with Empty Lists ([])\n",
        "\n",
        "Reason: Ensures missing values don’t break downstream operations when processing genres or countries. An empty list represents \"no data\" better than \"Unknown\".\n",
        "\n",
        "- Text-Based Column (description)\n",
        "Technique Used: Row Deletion (Dropped Missing Values)\n",
        "\n"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "numeric_columns = ['imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score']\n",
        "for col in numeric_columns:\n",
        "  Q1 = df_merged[col].quantile(0.25)\n",
        "  Q3 = df_merged[col].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  lower_bound = Q1 - 1.5 * IQR\n",
        "  upper_bound = Q3 + 1.5 * IQR\n",
        "  df_merged[col] = df_merged[col].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "\n",
        "\n",
        "outlier_summary = df_merged.describe()\n",
        "outlier_summary"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interquartile Range (IQR) Method to prevent distortions while preserving meaningful variations.\n",
        "\n",
        "- No extreme values remain beyond 1.5 x IQR.\n",
        "\n",
        "- Runtime, IMDb Score, Votes, TMDb Popularity, and TMDb Score are now within a controlled range.\n",
        "\n",
        "- Natural variations are still maintained (e.g., highly rated movies still have high IMDb scores, but extreme outliers are removed)."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "categorical_cols = df_merged.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_merged[col] = le.fit_transform(df_merged[col].astype(str))\n",
        "    label_encoders[col] = le"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applied Label Encoding for all ordinal categories."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "corr_matrix = df_merged.corr()\n",
        "\n",
        "# Visualizing correlation heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix, annot=False, cmap=\"coolwarm\", linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "current_year = 2025\n",
        "df_merged[\"release_age\"] = current_year - df_merged[\"release_year\"]\n",
        "df_merged[\"engagement_score\"] = df_merged[\"imdb_votes\"] * df_merged[\"imdb_score\"]\n",
        "\n",
        "drop_cols = [\"release_year\"]\n",
        "df_merged.drop(columns=drop_cols, inplace=True)\n",
        "df_merged.head()"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "var_thresh = VarianceThreshold(threshold=0.01)  # Remove near-constant features\n",
        "filtered_df = df_merged.copy()\n",
        "filtered_df = pd.DataFrame(var_thresh.fit_transform(filtered_df), columns=df_merged.columns[var_thresh.get_support()])\n",
        "\n",
        "\n",
        "corr_matrix = filtered_df.corr().abs()\n",
        "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
        "filtered_df.drop(columns=high_corr_features, inplace=True)\n",
        "\n",
        "X = filtered_df.drop(columns=[\"imdb_score\"])\n",
        "y = df_merged[\"imdb_score\"]\n",
        "mi_scores = mutual_info_regression(X, y)\n",
        "mi_scores_series = pd.Series(mi_scores, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "# Select top 15 most important features\n",
        "selected_features = mi_scores_series.head(15).index.tolist()\n",
        "filtered_df = filtered_df[selected_features + [\"imdb_score\"]]\n",
        "filtered_df.head()"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve model performance and remove irrelevant/redundant features, I uaed:\n",
        "\n",
        "Variance Threshold – Remove features with low variance (i.e., nearly constant values).\n",
        "\n",
        "Correlation Analysis – Drop highly correlated features to reduce multicollinearity.\n",
        "\n",
        "Feature Importance (Using Mutual Information) – Identify the most important features."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most important features influencing IMDb scores were identified using Mutual Information (MI) scores, highlighting key factors that shape audience perception and engagement. TMDb popularity, IMDb votes, and TMDb scores emerged as highly significant, as they directly reflect audience reception and critic evaluations. A higher number of votes typically signifies a well-known movie, while TMDb popularity captures real-time engagement trends. Runtime and release age also played crucial roles; longer films often receive polarized reviews based on genre and pacing, while older films can develop cult followings or benefit from nostalgia-driven ratings."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "skewed_cols = [\"imdb_votes\", \"tmdb_popularity\"]\n",
        "filtered_df[skewed_cols] = filtered_df[skewed_cols].apply(lambda x: np.log1p(x))  # log(1 + x) to handle zeros\n",
        "\n",
        "# Step 2: Standardization (Z-score normalization) for normally distributed features\n",
        "std_scaler = StandardScaler()\n",
        "std_cols = [\"runtime\", \"release_age\", \"seasons\"]\n",
        "filtered_df[std_cols] = std_scaler.fit_transform(filtered_df[std_cols])\n",
        "\n",
        "# Step 3: Min-Max Scaling for remaining numerical features\n",
        "minmax_scaler = MinMaxScaler()\n",
        "scaled_cols = list(set(filtered_df.columns) - set(std_cols) - set(skewed_cols) - {\"imdb_score\"})\n",
        "filtered_df[scaled_cols] = minmax_scaler.fit_transform(filtered_df[scaled_cols])\n",
        "\n",
        "filtered_df.head()"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "\n",
        "# Step 1: Determine the number of components needed to retain 95% variance\n",
        "pca = PCA(n_components=0.95)\n",
        "principal_components = pca.fit_transform(filtered_df.drop(columns=[\"imdb_score\"]))\n",
        "\n",
        "# Create a new dataframe with reduced dimensions\n",
        "pca_df = pd.DataFrame(principal_components, columns=[f\"PCA_{i+1}\" for i in range(principal_components.shape[1])])\n",
        "pca_df[\"imdb_score\"] = filtered_df[\"imdb_score\"].values\n",
        "\n",
        "# Check explained variance ratio\n",
        "explained_variance = pca.explained_variance_ratio_.sum()\n",
        "pca_df.head(), explained_variance"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applied PCA to remove redundant information and improve model efficiency."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "target = 'imdb_score'\n",
        "X = pca_df.drop(columns=[target])\n",
        "y = pca_df[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 80% Training Set: 94,636 samples\n",
        "\n",
        "- 20% Test Set: 23,660 samples"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(y_train, bins=20, kde=True, color=\"blue\")\n",
        "plt.title(\"Distribution of IMDb Scores in Training Set\")\n",
        "plt.xlabel(\"IMDb Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mWlss5ILTWH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram shows that IMDb scores are not perfectly balanced—certain score ranges dominate while others are underrepresented."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "bins = [0, 5, 7.5, 10]  # Define bin edges\n",
        "labels = ['low', 'medium', 'high']  # Define bin labels\n",
        "y_train_discretized = pd.cut(y_train, bins=bins, labels=labels)\n",
        "\n",
        "# Apply SMOTE to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_discretized)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(y_train_resampled, bins=20, kde=True, color=\"blue\")\n",
        "plt.title(\"Balanced IMDb Scores After SMOTE Oversampling\")\n",
        "plt.xlabel(\"IMDb Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balanced the dataset by using SMOTE to create a more even distribution."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: Train a model to predict imdb_score based on features like runtime, genres, release_year, and cast/crew.\n",
        "\n",
        "ML Model: Linear Regression, Random Forest, XGBoost. Features:\n",
        "\n",
        "release_year, runtime, genres (encoded) director, top actors (encoded) tmdb_popularity, imdb_votes"
      ],
      "metadata": {
        "id": "QQAA60blTpLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "target = 'imdb_score'\n",
        "features = [col for col in df_merged.columns if col != target and df_merged[col].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_merged[features], df_merged[target], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a RandomForest model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# making predicitons\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R-squared Score: {r2}\")"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics = ['MSE', 'MAE', 'R2 Score']\n",
        "scores = [mse, mae, r2]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metrics, scores, color=['blue', 'green', 'red'])\n",
        "plt.xlabel(\"Metrics\")\n",
        "plt.ylabel(\"Scores\")\n",
        "plt.title(\"Model Evaluation Metrics\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "fUcQQSQ4UFiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "import optuna\n",
        "from optuna.pruners import HyperbandPruner\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "# Fit the Algorithm\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 10, 30)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
        "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        bootstrap=bootstrap,\n",
        "        random_state=42\n",
        "    )\n",
        "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
        "    return -score\n",
        "\n",
        "# Run Bayesian Optimization with Optuna using Hyperband Pruner\n",
        "study = optuna.create_study(direction='minimize', pruner=HyperbandPruner())\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "best_model = RandomForestRegressor(**best_params, random_state=42)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_mse = -cv_scores.mean()\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Cross-Validation MSE: {cv_mse}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R-squared Score: {r2}\")"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used Bayesian Optimization with a Hyperband pruner for hyperparameter optimization in the model.\n",
        "\n",
        "Why Hyperband?\n",
        "\n",
        "Speed & Efficiency\n",
        "\n",
        "Unlike traditional Bayesian optimization, Hyperband dynamically allocates resources to the best-performing trials while quickly eliminating underperforming ones. It avoids wasting time on bad hyperparameter configurations early. Best for Large Search Spaces\n",
        "\n",
        "Since we are tuning multiple hyperparameters (e.g., n_estimators, max_depth, min_samples_split, etc.), Hyperband efficiently narrows down the best combination without needing exhaustive searches.\n",
        "\n",
        "Built-in Early Stopping\n",
        "\n",
        "Instead of evaluating all trials equally, it stops poor configurations early and focuses computational power on the best ones.\n",
        "\n",
        "Works Well with Optuna\n",
        "\n",
        "Optuna’s HyperbandPruner() is integrated seamlessly with your RandomForestRegressor, making it an ideal choice for optimizing its hyperparameters."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of evaluation metrics\n",
        "# metrics = ['Cross-Validation MSE', 'Test MSE', 'MAE', 'R2 Score']\n",
        "# scores = [cv_mse, mse, mae, r2]\n",
        "\n",
        "# plt.figure(figsize=(8, 5))\n",
        "# plt.bar(metrics, scores, color=['blue', 'orange', 'green', 'red'])\n",
        "# plt.xlabel(\"Metrics\")\n",
        "# plt.ylabel(\"Scores\")\n",
        "# plt.title(\"Model Evaluation Metrics with Hyperband Optimization\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "cPebQhfcU5KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a slight degradation meaning the Hyperband Optimization dealt with the overfitting."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Initialize the XGBoost Regressor model\n",
        "xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"XGBoost Regressor:\")\n",
        "print(f\"Mean Squared Error: {mse_xgb}\")\n",
        "print(f\"Mean Absolute Error: {mae_xgb}\")\n",
        "print(f\"R-squared Score: {r2_xgb}\")"
      ],
      "metadata": {
        "id": "4_CmmLjGVMfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of evaluation metrics\n",
        "metrics = ['MSE', 'MAE', 'R2 Score']\n",
        "scores_xgb = [mse_xgb, mae_xgb, r2_xgb]\n",
        "\n",
        "x = range(len(metrics))\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(x, scores_xgb, width=0.4, label='XGBoost', color='green', align='center')\n",
        "plt.xticks(x, metrics)\n",
        "plt.xlabel(\"Metrics\")\n",
        "plt.ylabel(\"Scores\")\n",
        "plt.title(\"XGBoost Regression Model Evaluation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0dzmz2fMVK4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import optuna\n",
        "import numpy as np\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
        "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
        "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 10.0),\n",
        "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 10.0)\n",
        "    }\n",
        "    model = XGBRegressor(**params, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    return mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "best_xgb_model = XGBRegressor(**best_params, random_state=42)\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Tuned XGBoost Regressor with Optuna:\")\n",
        "print(f\"Mean Squared Error: {mse_xgb}\")\n",
        "print(f\"Mean Absolute Error: {mae_xgb}\")\n",
        "print(f\"R-squared Score: {r2_xgb}\")"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've implemented Optuna Optimization for hyperparameter tuning and cross-validation on the XGBoost model because this is one of the fastest and most efficient methods."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There was a slight improvement in the R2 Score, making the accuracy of this model virtually similar to the RandomForest Regressor. The MSE and MAE significantly went down after tuning and cross-validation."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of evaluation metrics\n",
        "metrics = ['Test MSE', 'MAE', 'R2 Score']\n",
        "scores_xgb = [mse_xgb, mae_xgb, r2_xgb]\n",
        "\n",
        "x = range(len(metrics))\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(x, scores_xgb, width=0.4, label='Tuned XGBoost', color='green', align='center')\n",
        "plt.xticks(x, metrics)\n",
        "plt.xlabel(\"Metrics\")\n",
        "plt.ylabel(\"Scores\")\n",
        "plt.title(\"Tuned XGBoost Model Evaluation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l_9FQmRCVrIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose XGBoost Regressor as my final prediction model because it performs with the best accuracy with lesser chance of overfitting as compared to the Random Forest Regressor, also it has very low MAE and MSE meaning the model is performing with very less error in predicting the IMDb scores."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost (Extreme Gradient Boosting) is an optimized gradient boosting algorithm designed for efficiency, scalability, and high performance. It builds an ensemble of decision trees to improve predictive accuracy. The key advantages of XGBoost include:\n",
        "\n",
        "Gradient Boosting: Uses boosting technique to iteratively improve weak learners.\n",
        "\n",
        "Regularization (L1 & L2): Prevents overfitting.\n",
        "\n",
        "Handling Missing Data: Automatically manages missing values. Parallelization & Speed Optimization: Optimized for performance with GPU support."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "explainer = shap.Explainer(best_xgb_model, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# SHAP Summary Plot\n",
        "shap.summary_plot(shap_values, X_test)\n",
        "\n",
        "# SHAP Feature Importance Plot\n",
        "shap.plots.bar(shap_values)"
      ],
      "metadata": {
        "id": "qIvDYARMWIbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}